{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qLKZhhSarjr2"
      },
      "outputs": [],
      "source": [
        "!curl -sSOL https://downloads.apache.org/kafka/3.6.0/kafka_2.13-3.6.0.tgz\n",
        "!tar -xzf kafka_2.13-3.6.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHbc_gKeRWCV",
        "outputId": "19ee0aba-3008-4d2c-8a9b-0249dc5d58ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./kafka: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xcTIHJGerpQG"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.6.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.6.0/config/zookeeper.properties\n",
        "!./kafka_2.13-3.6.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.6.0/config/server.properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1eQmr9-12C2",
        "outputId": "681a49f3-232e-417d-9e44-b82c8b5ea2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=0f36e8ca2d04c51581cf77e0ff61a4e0310b1d45084640f04715d5e6e6683e9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install kafka-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "9hUSBpK5r8K-",
        "outputId": "936b3957-3221-4c3a-9166-f059b094a935"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5ddc3f2140>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4f3599ccb584:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>kafka-example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "scala_version = '2.12'\n",
        "spark_version = '3.5.0'\n",
        "packages = [ f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}' ,\n",
        "                                                'org.apache.kafka:kafka-clients:3.6.0']\n",
        "spark = SparkSession.builder.master(\"local\")\\\n",
        "                            .appName(\"kafka-example\")\\\n",
        "                            .config(\"spark.jars.packages\", \",\".join(packages))\\\n",
        "                            .getOrCreate()\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4IVyC3tmVp",
        "outputId": "71833c01-a547-4caa-c749-891840dec8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+------+---------+------+--------------------+-------------+\n",
            "| key|               value| topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+------+---------+------+--------------------+-------------+\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     0|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     1|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     2|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     3|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     4|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     5|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     6|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     7|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     8|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|     9|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    10|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    11|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    12|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    13|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    14|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    15|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    16|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    17|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    18|2023-11-23 04:53:...|            0|\n",
            "|NULL|[7B 22 6E 75 6D 6...|Number|        0|    19|2023-11-23 04:53:...|            0|\n",
            "+----+--------------------+------+---------+------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from kafka import KafkaProducer\n",
        "from json import dumps\n",
        "topic_name = 'Number'\n",
        "kafka_server = 'localhost:9092'\n",
        "producer = KafkaProducer(bootstrap_servers=kafka_server,\n",
        "                         value_serializer = lambda x:dumps(x).encode('utf-8'))\n",
        "for e in range(1000):\n",
        "    data = {'number' : e}\n",
        "    producer.send(topic_name, value=data)\n",
        "\n",
        "producer.flush()\n",
        "\n",
        "kafkaDf = spark.read.format(\"kafka\")\\\n",
        "                    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
        "                    .option(\"subscribe\", topic_name)\\\n",
        "                    .option(\"startingOffsets\", \"earliest\")\\\n",
        "                    .load()\n",
        "\n",
        "kafkaDf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhPatmdat46L"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.6.0/bin/kafka-console-consumer.sh --topic Number --from-beginning --bootstrap-server 127.0.0.1:9092"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XIBq7eMjuY3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb81f4c-22b7-42b9-a815-91cb777403aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+--------------+\n",
            "|topic_partition|offset|         value|\n",
            "+---------------+------+--------------+\n",
            "|       Number:0|     0| {\"number\": 0}|\n",
            "|       Number:0|     1| {\"number\": 1}|\n",
            "|       Number:0|     2| {\"number\": 2}|\n",
            "|       Number:0|     3| {\"number\": 3}|\n",
            "|       Number:0|     4| {\"number\": 4}|\n",
            "|       Number:0|     5| {\"number\": 5}|\n",
            "|       Number:0|     6| {\"number\": 6}|\n",
            "|       Number:0|     7| {\"number\": 7}|\n",
            "|       Number:0|     8| {\"number\": 8}|\n",
            "|       Number:0|     9| {\"number\": 9}|\n",
            "|       Number:0|    10|{\"number\": 10}|\n",
            "|       Number:0|    11|{\"number\": 11}|\n",
            "|       Number:0|    12|{\"number\": 12}|\n",
            "|       Number:0|    13|{\"number\": 13}|\n",
            "|       Number:0|    14|{\"number\": 14}|\n",
            "|       Number:0|    15|{\"number\": 15}|\n",
            "|       Number:0|    16|{\"number\": 16}|\n",
            "|       Number:0|    17|{\"number\": 17}|\n",
            "|       Number:0|    18|{\"number\": 18}|\n",
            "|       Number:0|    19|{\"number\": 19}|\n",
            "+---------------+------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# • Show the dataframe in a formatted way\n",
        "from pyspark.sql.functions import col, concat, lit\n",
        "kafkaDf.select(\n",
        "    concat(col(\"topic\"), lit(':'),\n",
        "    col(\"partition\").cast(\"string\")).alias(\"topic_partition\"),\n",
        "    col(\"offset\"),\n",
        "    col(\"value\").cast(\"string\")\n",
        "    ).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwr8StkhwqBW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}