{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_csv, col\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 23:19:27 WARN Utils: Your hostname, dothinh.local resolves to a loopback address: 127.0.0.1; using 192.168.1.2 instead (on interface en0)\n",
      "23/11/24 23:19:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/Cellar/apache-spark/3.5.0/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/dothinhtpr247gmai.com/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/dothinhtpr247gmai.com/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.kafka#kafka-clients added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-32e5e406-223d-4e8c-94c6-577085114412;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.6.0 in central\n",
      "\tfound com.github.luben#zstd-jni;1.5.5-1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.4 in central\n",
      ":: resolution report :: resolve 574ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.5.5-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.6.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.6.0] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 by [org.xerial.snappy#snappy-java;1.1.10.4] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   15  |   0   |   0   |   3   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-32e5e406-223d-4e8c-94c6-577085114412\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/15ms)\n",
      "23/11/24 23:19:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "scala_version = '2.12'\n",
    "spark_version = '3.5.0'\n",
    "packages = [ f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}' ,\n",
    "                                                'org.apache.kafka:kafka-clients:3.6.0']\n",
    "spark = SparkSession.builder.master(\"local\")\\\n",
    "                            .appName(\"Spotify Recommendation System\")\\\n",
    "                            .config(\"spark.jars.packages\", \",\".join(packages))\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark consumer for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 23:19:37 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/n4/b5xh84d97qzb6sptmp370phr0000gn/T/temporary-b7e3d6f1-7569-44b6-a9a1-8e5b7a89c114. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/11/24 23:19:37 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KAFKA_TOPIC_NAME_CONS = \"songTopic\"\n",
    "KAFKA_BOOTSTRAP_SERVERS_CONS = 'localhost:9092'\n",
    "\n",
    "# Construct a streaming DataFrame that reads from test-topic\n",
    "songs_df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS_CONS) \\\n",
    "        .option(\"subscribe\", KAFKA_TOPIC_NAME_CONS) \\\n",
    "        .option(\"startingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "songs_df1 = songs_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "\n",
    "\n",
    "songs_schema_string = \"order_id INT,id STRING, name STRING,popularity INT, duration_ms DOUBLE, explicit INT, \" \\\n",
    "                           + \"artists STRING, id_artists STRING, release_date STRING, \" \\\n",
    "                           + \"danceability DOUBLE,\" \\\n",
    "                           + \"energy DOUBLE, key INT, loudness DOUBLE, \" \\\n",
    "                           + \"mode INT,\" \\\n",
    "                           + \"speechiness DOUBLE,\" \\\n",
    "                           + \"acousticness DOUBLE, instrumentalness DOUBLE, liveness DOUBLE, \" \\\n",
    "                           + \"valence DOUBLE, tempo DOUBLE, time_signature DOUBLE\"\n",
    "\n",
    "\n",
    "\n",
    "songs_df2 = songs_df1 \\\n",
    "        .select(from_csv(col(\"value\"), songs_schema_string) \\\n",
    "                .alias(\"song\"), \"timestamp\")\n",
    "\n",
    "\n",
    "songs_df3 = songs_df2.select(\"song.*\", \"timestamp\")\n",
    "\n",
    "## Spark SQL View\n",
    "songs_df3.createOrReplaceTempView(\"song_find\");\n",
    "song_find_text = spark.sql(\"SELECT * FROM song_find\")\n",
    "songs_agg_write_stream = song_find_text \\\n",
    "        .writeStream \\\n",
    "        .trigger(processingTime='5 seconds') \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"truncate\", \"false\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"testedTable5\") \\\n",
    "        .start()\n",
    "\n",
    "songs_agg_write_stream.awaitTermination(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "# for x in range(2000):\n",
    "#         try:\n",
    "#                 print(\"Showing live view refreshed every 5 seconds\")\n",
    "#                 print(f\"Seconds passed: {x*5}\")\n",
    "#                 result = spark.sql(f'SELECT * from {songs_agg_write_stream.name}')\n",
    "#                 display(result.toPandas())\n",
    "#                 sleep(5)\n",
    "#                 clear_output(wait = True)\n",
    "#         except KeyboardInterrupt:\n",
    "#                 print(\"break\")\n",
    "#                 break\n",
    "# print(\"Live view ended...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from spotify_api import getSong\n",
    "song_data = getSong.passs()\n",
    "#song_data.rename(columns={'duration_s': 'duration_ms' }, inplace=True)\n",
    "song_data = song_data.drop(['id', 'added_at', 'time_signature','duration_s'], axis='columns')\n",
    "rand_n = random.randint(1,len(song_data))\n",
    "add_df = song_data.head(rand_n)[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>4so0Wek9Ig1p6CRCHuINwW</td>\n",
       "      <td>White Christmas</td>\n",
       "      <td>56</td>\n",
       "      <td>177480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BingCrosbyKenDarbySingersJohnScottTrotterHisOr...</td>\n",
       "      <td>ZjFtWeHPXNFeKSUeSUfPJgUmFFAVTqGVZiLpvygCZZlPMy...</td>\n",
       "      <td>1942-01-01</td>\n",
       "      <td>0.317</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.247</td>\n",
       "      <td>130.503</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-11-24 23:19:38.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2W889aLIKxULEefrleFBFI</td>\n",
       "      <td>Someone to Watch Over Me</td>\n",
       "      <td>54</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FrankSinatra</td>\n",
       "      <td>MxqyypSjfkZZLQVxS</td>\n",
       "      <td>1943</td>\n",
       "      <td>0.204</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.134</td>\n",
       "      <td>91.783</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-11-24 23:19:39.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                      id                      name  popularity  \\\n",
       "0        13  4so0Wek9Ig1p6CRCHuINwW           White Christmas          56   \n",
       "1        14  2W889aLIKxULEefrleFBFI  Someone to Watch Over Me          54   \n",
       "\n",
       "   duration_ms  explicit                                            artists  \\\n",
       "0     177480.0         0  BingCrosbyKenDarbySingersJohnScottTrotterHisOr...   \n",
       "1     198000.0         0                                       FrankSinatra   \n",
       "\n",
       "                                          id_artists release_date  \\\n",
       "0  ZjFtWeHPXNFeKSUeSUfPJgUmFFAVTqGVZiLpvygCZZlPMy...   1942-01-01   \n",
       "1                                  MxqyypSjfkZZLQVxS         1943   \n",
       "\n",
       "   danceability  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.317  ...   -16.485     1       0.0381         0.673   \n",
       "1         0.204  ...   -17.842     1       0.0418         0.947   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  \\\n",
       "0          0.353000     0.338    0.247  130.503             3.0   \n",
       "1          0.000009     0.321    0.134   91.783             3.0   \n",
       "\n",
       "                timestamp  \n",
       "0 2023-11-24 23:19:38.773  \n",
       "1 2023-11-24 23:19:39.775  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {songs_agg_write_stream.name}\")\n",
    "display(df.toPandas())\n",
    "df = df.sort(df.release_date.desc())\n",
    "\n",
    "df_stream = df\n",
    "\n",
    "df = df.drop('order_id',\n",
    "\t\t\t\t'id',\n",
    "\t\t\t\t'explicit',\n",
    "\t\t\t\t'mode',\n",
    "\t\t\t\t'release_date',\n",
    "\t\t\t\t'id_artists',\n",
    "\t\t\t\t'time_signature',\n",
    "\t\t\t\t'duration_ms',\n",
    "\t\t\t\t'timestamp')\n",
    "\n",
    "df_sp = spark.createDataFrame(add_df)\n",
    "train_df = df.union(df_sp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "\t\t\t\t\t\t\t\t\t\t'danceability',\n",
    "\t\t\t\t\t\t\t\t\t\t'energy',\n",
    "\t\t\t\t\t\t\t\t\t\t'loudness',\n",
    "\t\t\t\t\t\t\t\t\t\t'speechiness',\n",
    "\t\t\t\t\t\t\t\t\t\t'acousticness',\n",
    "\t\t\t\t\t\t\t\t\t\t'instrumentalness',\n",
    "\t\t\t\t\t\t\t\t\t\t'liveness',\n",
    "\t\t\t\t\t\t\t\t\t\t'valence',\n",
    "\t\t\t\t\t\t\t\t\t\t'tempo'\n",
    "         \t\t\t\t\t\t\t], \n",
    "                            outputCol='features')\n",
    "\n",
    "assembled_data = assembler.setHandleInvalid(\"skip\").transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scale = StandardScaler(inputCol='features', outputCol='standardized')\n",
    "\n",
    "data_scale = scale.fit(assembled_data)\n",
    "df = data_scale.transform(assembled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 23:19:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/11/24 23:19:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "silhouette_score = []\n",
    "evaluator = ClusteringEvaluator(predictionCol = 'prediction', \n",
    "                                featuresCol = 'standardized',\n",
    "                                metricName = 'silhouette',\n",
    "                                distanceMeasure = 'squaredEuclidean')\n",
    "\n",
    "\n",
    "KMeans_algo = KMeans(featuresCol = 'standardized', k = 3)\n",
    "    \n",
    "KMeans_fit = KMeans_algo.fit(df)\n",
    "    \n",
    "output_df = KMeans_fit.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>features</th>\n",
       "      <th>standardized</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What'd I Say</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1959.000</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>None</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.794</td>\n",
       "      <td>[1959.0, 0.54, 4.0, 1.0, 0.0508, 0.808, 0.0, 0...</td>\n",
       "      <td>[18553.099695110464, 5.012405988277569, 0.4002...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take Five</td>\n",
       "      <td>68</td>\n",
       "      <td>TheDaveBrubeckQuartet</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>8</td>\n",
       "      <td>-13.193</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.598</td>\n",
       "      <td>174.322</td>\n",
       "      <td>[0.454, 0.26, -13.193, 0.0401, 0.539, 0.00078,...</td>\n",
       "      <td>[4.299697428065417, 2.4133806610225332, -1.320...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue in Green (feat. John Coltrane &amp; Bill Evans)</td>\n",
       "      <td>65</td>\n",
       "      <td>MilesDavisJohnColtraneBillEvans</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>2</td>\n",
       "      <td>-25.358</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.154</td>\n",
       "      <td>110.479</td>\n",
       "      <td>[0.421, 0.0162, -25.358, 0.0388, 0.808, 0.0024...</td>\n",
       "      <td>[3.9871643551003095, 0.15037217964832705, -2.5...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I Only Have Eyes for You</td>\n",
       "      <td>62</td>\n",
       "      <td>TheFlamingos</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.410</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.303</td>\n",
       "      <td>88.554</td>\n",
       "      <td>[0.552, 0.313, -12.41, 0.0296, 0.916, 0.0017, ...</td>\n",
       "      <td>[5.227825947779978, 2.9053390265386647, -1.241...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny B. Goode</td>\n",
       "      <td>77</td>\n",
       "      <td>ChuckBerry</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>10</td>\n",
       "      <td>-9.129</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.969</td>\n",
       "      <td>167.983</td>\n",
       "      <td>[0.534, 0.803, -9.129, 0.0743, 0.741, 6.07e-05...</td>\n",
       "      <td>[5.057353362526284, 7.453633349234978, -0.9134...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name popularity  \\\n",
       "0                                      What'd I Say       None   \n",
       "1                                         Take Five         68   \n",
       "2  Blue in Green (feat. John Coltrane & Bill Evans)         65   \n",
       "3                          I Only Have Eyes for You         62   \n",
       "4                                   Johnny B. Goode         77   \n",
       "\n",
       "                           artists  danceability  energy   key  loudness  \\\n",
       "0                                0      1959.000  0.5400  None     4.000   \n",
       "1            TheDaveBrubeckQuartet         0.454  0.2600     8   -13.193   \n",
       "2  MilesDavisJohnColtraneBillEvans         0.421  0.0162     2   -25.358   \n",
       "3                     TheFlamingos         0.552  0.3130     5   -12.410   \n",
       "4                       ChuckBerry         0.534  0.8030    10    -9.129   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       1.0000        0.0508          0.808000    0.0000    0.162    0.794   \n",
       "1       0.0401        0.5390          0.000780    0.0675    0.598  174.322   \n",
       "2       0.0388        0.8080          0.002400    0.0978    0.154  110.479   \n",
       "3       0.0296        0.9160          0.001700    0.1200    0.303   88.554   \n",
       "4       0.0743        0.7410          0.000061    0.3070    0.969  167.983   \n",
       "\n",
       "                                            features  \\\n",
       "0  [1959.0, 0.54, 4.0, 1.0, 0.0508, 0.808, 0.0, 0...   \n",
       "1  [0.454, 0.26, -13.193, 0.0401, 0.539, 0.00078,...   \n",
       "2  [0.421, 0.0162, -25.358, 0.0388, 0.808, 0.0024...   \n",
       "3  [0.552, 0.313, -12.41, 0.0296, 0.916, 0.0017, ...   \n",
       "4  [0.534, 0.803, -9.129, 0.0743, 0.741, 6.07e-05...   \n",
       "\n",
       "                                        standardized  prediction  \n",
       "0  [18553.099695110464, 5.012405988277569, 0.4002...           1  \n",
       "1  [4.299697428065417, 2.4133806610225332, -1.320...           1  \n",
       "2  [3.9871643551003095, 0.15037217964832705, -2.5...           2  \n",
       "3  [5.227825947779978, 2.9053390265386647, -1.241...           1  \n",
       "4  [5.057353362526284, 7.453633349234978, -0.9134...           1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 00:11:10 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:10 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:10 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:11 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:12 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:13 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:14 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:15 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:16 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:17 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:18 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:19 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/11/25 00:11:20 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n"
     ]
    }
   ],
   "source": [
    "output_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 29599.89it/s]                              \n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class SpotifyRecommender():\n",
    "    def __init__(self, rec_data):\n",
    "        self.rec_data_ = rec_data\n",
    "    \n",
    "    def spotify_recommendations(self, song_name, amount=1):\n",
    "        distances = []\n",
    "        song = self.rec_data_[(self.rec_data_.name.str.lower() == song_name.lower())]\\\n",
    "                                                                    .head(1).values[0]\n",
    "        # get details of our fav song from name we pass as x earlier.\n",
    "        res_data = self.rec_data_[self.rec_data_.name.str.lower() != song_name.lower()]\n",
    "        #dropping the data with our fav song so that it doesnt affect our recommendation.\n",
    "        for r_song in tqdm(res_data.values):\n",
    "            # tqdm is just used for showing the bar of iteration through our streamed songs.\n",
    "            dist = 0\n",
    "            for col in np.arange(len(res_data.columns)):\n",
    "                # (len(res_data.columns) gets us the number of columns -> 13 in our case.\n",
    "                #indeces of non-numerical columns neednt be considered.\n",
    "                if not col in [0,1,13]:\n",
    "                    #calculating the manhettan distances for each numerical feature\n",
    "                    # song -> from our fav dataset.\n",
    "                    # r_song -> from streaming data.\n",
    "                    dist = dist + np.absolute(float(song[col]) - float(r_song[col]))\n",
    "            distances.append(dist)\n",
    "            # distances are calculated and appended and added to a new column called distances in our dataset.\n",
    "        res_data['distance'] = distances\n",
    "        #sorting our data to be ascending by 'distance' feature\n",
    "        res_data = res_data.sort_values('distance')\n",
    "        # resulting dataset have the song similar to our fav song's numerical values and thus recommended.\n",
    "        columns = ['name', 'artists', \n",
    "                   'acousticness', 'liveness', \n",
    "                   'instrumentalness', 'energy', \n",
    "                   'danceability', 'valence']\n",
    "        \n",
    "        return res_data[columns][:amount]\n",
    "    \n",
    "    \n",
    "datad = output_df.select('name',\n",
    "                        'artists',\n",
    "                        'danceability',\n",
    "                        'energy',\n",
    "                        'key',\n",
    "                        'loudness',\n",
    "                        'speechiness',\n",
    "                        'acousticness',\n",
    "                        'instrumentalness',\n",
    "                        'liveness',\n",
    "                        'valence',\n",
    "                        'tempo',\n",
    "                        'prediction')\n",
    "\n",
    "\n",
    "\n",
    "datf = datad.toPandas()\n",
    "datf.drop(datf[datf['artists'] == '0'].index, inplace = True)\n",
    "datf.drop_duplicates(inplace=True)\n",
    "datf.drop(datf[datf['danceability'] == 0.0000].index, inplace = True)\n",
    "datf.drop(datf[datf['liveness'] == 0.000].index, inplace = True)\n",
    "datf.drop(datf[datf['instrumentalness'] == 0.000000].index, inplace = True)\n",
    "datf.drop(datf[datf['energy'] == 0.0000].index, inplace = True)\n",
    "datf.drop(datf[datf['danceability'] == 0.000].index, inplace = True)\n",
    "datf.drop(datf[datf['valence'] == 0.000].index, inplace = True)\n",
    "\n",
    "y = datf\n",
    "value_pred = datf.iloc[-1:]['prediction']\n",
    "#datf = datf[datf['prediction'] == list(value_pred)[0]]\n",
    "\n",
    "recommender = SpotifyRecommender(datf)\n",
    "x = add_df['name'].tolist()[0]\n",
    "\n",
    "rec_song = recommender.spotify_recommendations(x, 10)\n",
    "\n",
    "v = add_df[['name', 'artists',  'acousticness', 'liveness', 'instrumentalness', 'energy', \n",
    "       'danceability', 'valence']]\n",
    "\n",
    "rec_song = pd.concat([rec_song, v])\n",
    "rec_song.to_csv('rec_song.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------+----------------+------+------------+-------+\n",
      "|                name|             artists|acousticness|liveness|instrumentalness|energy|danceability|valence|\n",
      "+--------------------+--------------------+------------+--------+----------------+------+------------+-------+\n",
      "|Again (with The M...| DorisDayTheMellomen|       0.981|  0.0753|         1.13E-6|0.0209|       0.495|  0.145|\n",
      "|I Can't Quit You ...|         WillieDixon|       0.407|   0.215|          0.0434| 0.236|       0.469|  0.415|\n",
      "|    Gymnopédie No. 1|ErikSatiePhilippe...|       0.994|  0.0941|           0.937|0.0128|       0.469|  0.354|\n",
      "|Someone to Watch ...|        FrankSinatra|       0.947|   0.321|         9.15E-6| 0.151|       0.204|  0.134|\n",
      "|Put Your Dreams A...|        FrankSinatra|        0.95|   0.152|           0.276|0.0546|       0.197|    0.1|\n",
      "|Contigo - Tema Re...|          LosPanchos|       0.979|   0.102|         8.53E-4| 0.297|       0.789|   0.73|\n",
      "|Sin Ti - Remaster...|          LosPanchos|       0.969|    0.14|          0.0204| 0.382|       0.674|  0.571|\n",
      "|Saturday Night (I...|        FrankSinatra|        0.84|   0.788|         1.52E-6| 0.335|       0.561|   0.59|\n",
      "|     White Christmas|BingCrosbyKenDarb...|       0.673|   0.338|           0.353| 0.158|       0.317|  0.247|\n",
      "|Nancy (With the L...|        FrankSinatra|       0.984|   0.156|         3.58E-4|0.0826|       0.295|  0.169|\n",
      "|    Treat You Better|        Shawn Mendes|       0.106|   0.107|             0.0| 0.819|       0.444|  0.747|\n",
      "+--------------------+--------------------+------------+--------+----------------+------+------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_rec = spark.createDataFrame(rec_song)\n",
    "df_rec.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
